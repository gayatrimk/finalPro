# -*- coding: utf-8 -*-
"""Backend.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BDSwtbplJVh42xqb6hDzgYV7-haXxpgt
"""
import os
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import re
import requests
from flask import Flask, request, jsonify
from google.cloud import vision
from flask_cors import CORS
import joblib  # For saving and loading the model
import cv2
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import pytesseract
from PIL import Image
import io
import base64
import json
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure Google AI
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))

app = Flask(__name__)
client = vision.ImageAnnotatorClient.from_service_account_file('acc.json')
CORS(app, resources={r"/*": {"origins": "*"}})

# Define paths for the model and scaler
MODEL_PATH = 'food_classification_model.h5'
SCALER_PATH = 'scaler.pkl'
ENCODER_PATH = 'encoder.pkl'
CSV_PATH = os.path.join(os.path.dirname(__file__), 'Biscuits_sample.csv')  # Adjust path if needed

nutrition_keys = [
    "Energy", "Calories", "Protein", "Carbohydrate", "Of which Sugar", "Total Carbohydrate",
    "Fat", "Total Fat", "Saturated Fat", "Trans Fat", "Cholesterol", "Sodium",
    "Sugars", "Added Sugars", "Dietary Fiber", "Fiber",
    "Monounsaturated fatty acids", "Polyunsaturated fatty acids"
]

safe_limits_per_100g = {
    "ENERGY(kcal)": 250,     # kcal
    "PROTEIN": 5,           # g (below this is harmful)
    "TOTAL SUGARS": 10,      # g
    "TOTAL FAT": 17,         # g
    "SODIUM(mg)": 600,       # mg
}

def load_dataset():
    df = pd.read_csv(CSV_PATH)
    return df

def classify_food(row):
    sugar = row["TOTAL SUGARS"]
    fat = row["TOTAL FAT"]
    sodium = row["SODIUM(mg)"]

    harmful_factors = 0
    harmful_nutrients = []

    sodium_ratio = sodium / safe_limits_per_100g["SODIUM(mg)"]
    fat_ratio = fat / safe_limits_per_100g["TOTAL FAT"]
    sugar_ratio = sugar / safe_limits_per_100g["TOTAL SUGARS"]

    if sodium_ratio > 3 or fat_ratio > 3 or sugar_ratio > 3:
        harmful_nutrients.append("excessive amounts of sodium, fat, or sugar")
        return "Very Harmful", harmful_nutrients

    if sodium_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high sodium")
    if fat_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high fat")
    if sugar_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high sugar")

    if harmful_factors >= 2:
        return "Harmful", harmful_nutrients

    if harmful_factors == 1:
        return "OK", harmful_nutrients

    return "Safe", []

# Load the dataset and preprocess it only if the model files don't exist
if not os.path.exists(MODEL_PATH) or not os.path.exists(SCALER_PATH) or not os.path.exists(ENCODER_PATH):
    data = load_dataset()
    data_c = data.replace(np.nan, 0)

    data_c["TOTAL SUGARS"] = data_c["TOTAL SUGARS"].astype(float)
    data_c["TOTAL FAT"] = data_c["TOTAL FAT"].astype(float)
    data_c["SODIUM(mg)"] = data_c["SODIUM(mg)"].astype(float)

    data_c[["Category", "Reasons"]] = data_c.apply(classify_food, axis=1, result_type="expand")

    X = data_c[["TOTAL SUGARS", "TOTAL FAT", "SODIUM(mg)"]].values
    y = data_c["Category"].values

    # Encode labels
    encoder = OneHotEncoder(sparse_output=False)
    y_encoded = encoder.fit_transform(y.reshape(-1, 1))
    joblib.dump(encoder, ENCODER_PATH)  # Save the encoder

    # Split dataset
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

    # Normalize features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    joblib.dump(scaler, SCALER_PATH)  # Save the scaler

    # ANN Model
    model = keras.Sequential([
        keras.layers.Dense(8, activation="relu", input_shape=(3,)),
        keras.layers.Dense(4, activation="relu"),
        keras.layers.Dense(4, activation="softmax")
    ])

    # Compile Model
    model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

    # Train Model
    model.fit(X_train, y_train, epochs=30, batch_size=4, validation_data=(X_test, y_test), verbose=0)  # Reduced verbosity

    # Evaluate Model
    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"Test Accuracy (Training): {accuracy:.2f}")

    # Save the model
    model.save(MODEL_PATH)
    print(f"Trained model saved to {MODEL_PATH}")
else:
    # Load the trained model, scaler, and encoder
    try:
        # First try loading with the newer format
        model = tf.keras.models.load_model(MODEL_PATH, compile=False)
    except:
        try:
            # If that fails, try with custom objects
            model = keras.models.load_model(MODEL_PATH, custom_objects={'InputLayer': tf.keras.layers.InputLayer})
        except:
            # If both fail, try loading with legacy format
            model = tf.keras.models.load_model(MODEL_PATH, compile=False, custom_objects={'InputLayer': tf.keras.layers.InputLayer})
    
    scaler = joblib.load(SCALER_PATH)
    encoder = joblib.load(ENCODER_PATH)
    print(f"Loaded trained model from {MODEL_PATH}")

@app.route("/ocr", methods=["POST"])
def newFun():
    print("Inside flask backend")
    try:
        if 'image' not in request.files:
            print("No image file in request")
            return jsonify({'error': 'No image file provided'}), 400

        image_file = request.files['image']
        if image_file.filename == '':
            print("Empty filename")
            return jsonify({'error': 'No selected image file'}), 400

        print(f"Received file: {image_file.filename}")
        
        # Read image bytes
        image_bytes = image_file.read()
        if not image_bytes:
            print("Empty image file")
            return jsonify({'error': 'Empty image file'}), 400

        # Create Vision API image object
        image = vision.Image(content=image_bytes)
        
        # Perform OCR
        try:
            response = client.document_text_detection(image=image)
        except Exception as e:
            print(f"Vision API error: {str(e)}")
            return jsonify({'error': f'Vision API error: {str(e)}'}), 500

        if response.error.message:
            print(f"Vision API error message: {response.error.message}")
            return jsonify({'error': response.error.message}), 500

        # Process the text
        full_text = response.full_text_annotation.text
        cleaned_text = re.sub(r'[\s]{2,}', ' ', full_text).strip()
        print(f"Extracted text: {cleaned_text[:100]}...")  # Print first 100 chars

        # Extract nutrition data
        nutrition_data = {}
        for key in nutrition_keys:
            pattern = rf'{key}[^\d]*([\d.]+)\s*(kcal|g|mg|kJ|%)?'
            match = re.search(pattern, cleaned_text, re.IGNORECASE)
            if match:
                value_str = match.group(1)
                try:
                    value = float(value_str)
                    unit = match.group(2) if match.group(2) else ''
                    nutrition_data[key] = {'value': value, 'unit': unit.strip()}
                except ValueError:
                    print(f"Warning: Could not convert value '{value_str}' for {key} to float.")

        print("Extracted Nutrition Data:", nutrition_data)

        # Process nutrition values
        sugar_info = nutrition_data.get("Sugars") or nutrition_data.get("Total Sugars") or nutrition_data.get("Of which Sugar")
        fat_info = nutrition_data.get("Total Fat") or nutrition_data.get("Fat")
        sodium_value = 0.0
        
        # Extract sodium value
        if "Sodium" in nutrition_data and isinstance(nutrition_data["Sodium"], dict) and 'value' in nutrition_data["Sodium"]:
            sodium_value = nutrition_data["Sodium"]["value"]
        elif "sodium" in nutrition_data and isinstance(nutrition_data["sodium"], dict) and 'value' in nutrition_data["sodium"]:
            sodium_value = nutrition_data["sodium"]["value"]
        elif any("sodium" in k.lower() for k in nutrition_data):
            for key, value_dict in nutrition_data.items():
                if "sodium" in key.lower() and isinstance(value_dict, dict) and 'value' in value_dict:
                    sodium_value = value_dict['value']
                    break

        sugar_value = sugar_info['value'] if sugar_info and 'value' in sugar_info else 0.0
        fat_value = fat_info['value'] if fat_info and 'value' in fat_info else 0.0

        print(f"Processed values - Sugar: {sugar_value}, Fat: {fat_value}, Sodium: {sodium_value}")

        # Prepare data for prediction
        new_data = np.array([[sugar_value, fat_value, sodium_value]])
        new_data_scaled = scaler.transform(new_data)
        
        # Make prediction
        try:
            prediction = model.predict(new_data_scaled)
            predicted_class = encoder.inverse_transform(prediction)[0][0]
            print(f"Predicted class: {predicted_class}")
            
            # Prepare response
            response_data = {
                'message': f"This food is {predicted_class}",
                'explanation': f"Based on the nutritional values: Sugar ({sugar_value}g), Fat ({fat_value}g), Sodium ({sodium_value}mg)",
                'nutrition_data': nutrition_data
            }
            
            return jsonify(response_data)
            
        except Exception as e:
            print(f"Prediction error: {str(e)}")
            return jsonify({'error': f'Prediction error: {str(e)}'}), 500

    except Exception as e:
        print(f"General error: {str(e)}")
        return jsonify({'error': f'Server error: {str(e)}'}), 500

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({"status": "healthy"}), 200

if __name__ == "__main__":
    # Update the host to '0.0.0.0' to allow connections from any IP
    app.run(host='0.0.0.0', port=5001, debug=True)