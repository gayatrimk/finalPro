# -*- coding: utf-8 -*-
"""Backend.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BDSwtbplJVh42xqb6hDzgYV7-haXxpgt
"""
import os
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import re
import requests
from flask import Flask, request, jsonify
from google.cloud import vision
from flask_cors import CORS
import joblib  # For saving and loading the model

app = Flask(__name__)
client = vision.ImageAnnotatorClient.from_service_account_file('acc.json')
CORS(app)  # Enable CORS for localhost frontend

# Define paths for the model and scaler
MODEL_PATH = 'food_classification_model.h5'
SCALER_PATH = 'scaler.pkl'
ENCODER_PATH = 'encoder.pkl'
CSV_PATH = os.path.join(os.path.dirname(__file__), 'Biscuits_sample.csv')  # Adjust path if needed

nutrition_keys = [
    "Energy", "Calories", "Protein", "Carbohydrate", "Of which Sugar", "Total Carbohydrate",
    "Fat", "Total Fat", "Saturated Fat", "Trans Fat", "Cholesterol", "Sodium",
    "Sugars", "Added Sugars", "Dietary Fiber", "Fiber",
    "Monounsaturated fatty acids", "Polyunsaturated fatty acids"
]

safe_limits_per_100g = {
    "ENERGY(kcal)": 250,     # kcal
    "PROTEIN": 5,           # g (below this is harmful)
    "TOTAL SUGARS": 10,      # g
    "TOTAL FAT": 17,         # g
    "SODIUM(mg)": 600,       # mg
}

def load_dataset():
    df = pd.read_csv(CSV_PATH)
    return df

def classify_food(row):
    sugar = row["TOTAL SUGARS"]
    fat = row["TOTAL FAT"]
    sodium = row["SODIUM(mg)"]

    harmful_factors = 0
    harmful_nutrients = []

    sodium_ratio = sodium / safe_limits_per_100g["SODIUM(mg)"]
    fat_ratio = fat / safe_limits_per_100g["TOTAL FAT"]
    sugar_ratio = sugar / safe_limits_per_100g["TOTAL SUGARS"]

    if sodium_ratio > 3 or fat_ratio > 3 or sugar_ratio > 3:
        harmful_nutrients.append("excessive amounts of sodium, fat, or sugar")
        return "Very Harmful", harmful_nutrients

    if sodium_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high sodium")
    if fat_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high fat")
    if sugar_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high sugar")

    if harmful_factors >= 2:
        return "Harmful", harmful_nutrients

    if harmful_factors == 1:
        return "OK", harmful_nutrients

    return "Safe", []

# Load the dataset and preprocess it only if the model files don't exist
if not os.path.exists(MODEL_PATH) or not os.path.exists(SCALER_PATH) or not os.path.exists(ENCODER_PATH):
    data = load_dataset()
    data_c = data.replace(np.nan, 0)

    data_c["TOTAL SUGARS"] = data_c["TOTAL SUGARS"].astype(float)
    data_c["TOTAL FAT"] = data_c["TOTAL FAT"].astype(float)
    data_c["SODIUM(mg)"] = data_c["SODIUM(mg)"].astype(float)

    data_c[["Category", "Reasons"]] = data_c.apply(classify_food, axis=1, result_type="expand")

    X = data_c[["TOTAL SUGARS", "TOTAL FAT", "SODIUM(mg)"]].values
    y = data_c["Category"].values

    # Encode labels
    encoder = OneHotEncoder(sparse_output=False)
    y_encoded = encoder.fit_transform(y.reshape(-1, 1))
    joblib.dump(encoder, ENCODER_PATH)  # Save the encoder

    # Split dataset
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

    # Normalize features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    joblib.dump(scaler, SCALER_PATH)  # Save the scaler

    # ANN Model
    model = keras.Sequential([
        keras.layers.Dense(8, activation="relu", input_shape=(3,)),
        keras.layers.Dense(4, activation="relu"),
        keras.layers.Dense(4, activation="softmax")
    ])

    # Compile Model
    model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

    # Train Model
    model.fit(X_train, y_train, epochs=30, batch_size=4, validation_data=(X_test, y_test), verbose=0)  # Reduced verbosity

    # Evaluate Model
    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"Test Accuracy (Training): {accuracy:.2f}")

    # Save the model
    model.save(MODEL_PATH)
    print(f"Trained model saved to {MODEL_PATH}")
else:
    # Load the trained model, scaler, and encoder
    model = keras.models.load_model(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    encoder = joblib.load(ENCODER_PATH)
    print(f"Loaded trained model from {MODEL_PATH}")

@app.route("/ocr", methods=["POST"])
def newFun():
    print("Inside flask backend")
    if 'image' not in request.files:
        return jsonify({'error': 'No image file provided'}), 400

    image_file = request.files['image']
    if image_file.filename == '':
        return jsonify({'error': 'No selected image file'}), 400

    try:
        image_bytes = image_file.read()
        image = vision.Image(content=image_bytes)
        response = client.document_text_detection(image=image)

        if response.error.message:
            return jsonify({'error': response.error.message}), 500

        full_text = response.full_text_annotation.text
        cleaned_text = re.sub(r'[\s]{2,}', ' ', full_text).strip()

        nutrition_data = {}
        for key in nutrition_keys:
            pattern = rf'{key}[^\d]*([\d.]+)\s*(kcal|g|mg|kJ|%)?'
            match = re.search(pattern, cleaned_text, re.IGNORECASE)
            if match:
                value_str = match.group(1)
                try:
                    value = float(value_str)
                    unit = match.group(2) if match.group(2) else ''
                    nutrition_data[key] = {'value': value, 'unit': unit.strip()}
                except ValueError:
                    print(f"Warning: Could not convert value '{value_str}' for {key} to float.")

        print("Extracted Nutrition Data:", nutrition_data)

        sugar_info = nutrition_data.get("Sugars") or nutrition_data.get("Total Sugars") or nutrition_data.get("Of which Sugar")
        fat_info = nutrition_data.get("Total Fat") or nutrition_data.get("Fat")
        sodium_value = 0.0
        if "Sodium" in nutrition_data and isinstance(nutrition_data["Sodium"], dict) and 'value' in nutrition_data["Sodium"]:
            sodium_value = nutrition_data["Sodium"]["value"]
        elif "sodium" in nutrition_data and isinstance(nutrition_data["sodium"], dict) and 'value' in nutrition_data["sodium"]:
            sodium_value = nutrition_data["sodium"]["value"]
        elif any("sodium" in k.lower() for k in nutrition_data): # Check for "sodium" (case-insensitive) in keys
            for key, value_dict in nutrition_data.items():
                if "sodium" in key.lower() and isinstance(value_dict, dict) and 'value' in value_dict:
                    sodium_value = value_dict['value']
                    break

        sugar_value = sugar_info['value'] if sugar_info and 'value' in sugar_info else 0.0
        fat_value = fat_info['value'] if fat_info and 'value' in fat_info else 0.0
        #sodium_value = sodium_info['value'] if sodium_info and 'value' in sodium_info else 0.0

        print(f"Sugar: {sugar_value}, Fat: {fat_value}, Sodium: {sodium_value}")

        new_data = np.array([[sugar_value, fat_value, sodium_value]])
        new_data_scaled = scaler.transform(new_data)
        prediction = model.predict(new_data_scaled)

        # Get predicted category
        predicted_index = np.argmax(prediction)
        predicted_label_encoded = np.zeros_like(prediction)
        predicted_label_encoded[0][predicted_index] = 1
        predicted_label = encoder.inverse_transform(predicted_label_encoded)[0][0]

        # Use classification logic to explain why
        temp_row = pd.Series({"TOTAL SUGARS": sugar_value, "TOTAL FAT": fat_value, "SODIUM(mg)": sodium_value})
        _, reasons = classify_food(temp_row)
        explanation = f" As the product contains {' and '.join(reasons)}." if reasons else " The product is within safe limits."

        # Display result
        print(f"Predicted Category: {predicted_label}{explanation}")

        return jsonify({"message": f"Model Prediction: {predicted_label}", "explanation": explanation, "nutrition_data": nutrition_data}), 200

    except Exception as e:
        print(f"Error processing image: {e}")
        return jsonify({'error': f'Failed to process image: {str(e)}'}), 500

if __name__ == "__main__":
    app.run(debug=True, port=5001) # Ensure the port matches your frontend