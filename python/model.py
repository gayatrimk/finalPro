# -*- coding: utf-8 -*-
"""Trial Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BDSwtbplJVh42xqb6hDzgYV7-haXxpgt
"""
import os
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import re
import requests
from flask import Flask, request, jsonify
from google.cloud import vision

from flask import Flask, request, jsonify
from flask_cors import CORS

app = Flask(__name__)
client = vision.ImageAnnotatorClient.from_service_account_file('acc.json')
CORS(app)  # Enable CORS for localhost frontend


nutrition_keys = [
    "Energy", "Calories", "Protein", "Carbohydrate", "Of which Sugar", "Total Carbohydrate",
    "Fat", "Total Fat", "Saturated Fat", "Trans Fat", "Cholesterol", "Sodium",
    "Sugars", "Added Sugars", "Dietary Fiber", "Fiber",
    "Monounsaturated fatty acids", "Polyunsaturated fatty acids"
]
def load_dataset(): 
    csv_path = os.path.join('D:/Desktop/Final_Proj/flask', 'data', 'BiscuitData.csv') 
    df = pd.read_csv(csv_path) 
    return df

data=load_dataset()
data_c = data.replace(np.nan, 0)
safe_limits_per_100g = {
    "ENERGY(kcal)": 250,   # kcal
    "PROTEIN": 5,          # g (below this is harmful)
    "TOTAL SUGARS": 10,    # g
    "TOTAL FAT": 17,       # g
    "SODIUM(mg)": 600,     # mg
}
def classify_food(row):
    sugar = row["TOTAL SUGARS"]
    fat = row["TOTAL FAT"]
    sodium = row["SODIUM(mg)"]

    harmful_factors = 0

    sodium_ratio = sodium / safe_limits_per_100g["SODIUM(mg)"]
    fat_ratio = fat / safe_limits_per_100g["TOTAL FAT"]
    sugar_ratio = sugar / safe_limits_per_100g["TOTAL SUGARS"]


    #print(f"Ratios: sodium_ratio={sodium_ratio:.2f}, fat_ratio={fat_ratio:.2f}, sugar_ratio={sugar_ratio:.2f}")

    # Identify which nutrients contribute to harmful classification
    harmful_nutrients = []

    if sodium_ratio > 3 or fat_ratio > 3 or sugar_ratio > 3:
        harmful_nutrients.append("excessive amounts of sodium, fat, or sugar")
        return "Very Harmful", harmful_nutrients

    if sodium_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high sodium")
    if fat_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high fat")
    if sugar_ratio > 2:
        harmful_factors += 1
        harmful_nutrients.append("high sugar")

    #print(f"Ratios:sodium_ratio{sodium_ratio},fat_ratio{fat_ratio},sugar_ratio{sugar_ratio}")


    if harmful_factors >= 2:
        return "Harmful", harmful_nutrients

    if harmful_factors == 1:
        return "OK", harmful_nutrients

    return "Safe", []


# Apply classification function
data_c["TOTAL SUGARS"] = data_c["TOTAL SUGARS"].astype(float)
data_c["TOTAL FAT"] = data_c["TOTAL FAT"].astype(float)
data_c["SODIUM(mg)"] = data_c["SODIUM(mg)"].astype(float)

data_c[["Category", "Reasons"]] = data_c.apply(classify_food, axis=1, result_type="expand")

X = data_c[["TOTAL SUGARS", "TOTAL FAT", "SODIUM(mg)"]].values
y = data_c["Category"].values

# Encode labels
encoder = OneHotEncoder(sparse_output=False)
y_encoded = encoder.fit_transform(y.reshape(-1, 1))

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# Normalize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ANN Model
model = keras.Sequential([
    keras.layers.Dense(8, activation="relu", input_shape=(3,)),
    keras.layers.Dense(4, activation="relu"),
    keras.layers.Dense(4, activation="softmax")
])

# Compile Model
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# Train Model
model.fit(X_train, y_train, epochs=30, batch_size=4, validation_data=(X_test, y_test))

# Evaluate Model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy:.2f}")

@app.route("/model", methods=["POST"])
def newFun():
    print("Inside flask backend")
    data = request.json
    image_url = data.get('imageUrl')
    if not image_url:
        return jsonify({'error': 'No image URL provided'}), 400

    try:
        response = requests.get(image_url)
        response.raise_for_status()
        image_bytes = response.content
    except Exception as e:
        return jsonify({'error': f'Failed to fetch image from URL: {str(e)}'}), 500

    image = vision.Image(content=image_bytes)
    response = client.document_text_detection(image=image)

    if response.error.message:
        return jsonify({'error': response.error.message}), 500

    full_text = response.full_text_annotation.text
    cleaned_text = re.sub(r'[\s]{2,}', ' ', full_text).strip()

    nutrition_data = {}
    for key in nutrition_keys:
        pattern = rf'{key}[^\d]*([\d.]+)\s*(kcal|g|mg|kJ|%)?'
        match = re.search(pattern, cleaned_text, re.IGNORECASE)
        if match:
            value = match.group(1) + (f" {match.group(2)}" if match.group(2) else '')
            nutrition_data[key] = value
   
   
    sugar = nutrition_data.get("Sugars")
    fat = nutrition_data.get("Total Fat")
    sodium = data.get("Sodium")
    
    print(f"Sugar: {sugar}, Fat: {fat}, Sodium: {sodium}")

    new_data = np.array([[sugar,fat,sodium]])
    new_data_scaled = scaler.transform(new_data)
    prediction = model.predict(new_data_scaled)

    # Get predicted category
    predicted_label = encoder.inverse_transform(prediction)[0]

    # Use classification logic to explain why
    reasons = classify_food(new_data[0])
    explanation = f" As the product contains {' and '.join(reasons)}." if reasons else " The product is within safe limits."

    # Display result
    print(f"Predicted Category: {predicted_label}{explanation}")

    return jsonify({"message": f"model Predicton:{predicted_label}"}), 200

if __name__ == "__main__":
    app.run(debug=True)
